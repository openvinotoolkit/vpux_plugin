//
// Copyright (C) 2024 Intel Corporation.
// SPDX-License-Identifier: Apache 2.0
//
//

#include "vpux/compiler/core/attributes/dim.hpp"
#include "vpux/compiler/core/attributes/shape.hpp"
#include "vpux/compiler/core/tiling.hpp"
#include "vpux/compiler/dialect/VPU/IR/attributes.hpp"
#include "vpux/compiler/dialect/VPU/IR/ops.hpp"
#include "vpux/compiler/dialect/VPU/utils/const_utils.hpp"
#include "vpux/compiler/dialect/VPU/utils/distributed_tensor_utils.hpp"
#include "vpux/compiler/dialect/VPU/utils/explicit_distribution_utils.hpp"

#include <algorithm>
#include <unordered_set>
#include <utility>

using namespace vpux;

mlir::LogicalResult vpux::VPU::MatMulOp::inferReturnTypes(mlir::MLIRContext* ctx, std::optional<mlir::Location> optLoc,
                                                          mlir::ValueRange operands, mlir::DictionaryAttr attrs,
                                                          mlir::OpaqueProperties, mlir::RegionRange /*regions*/,
                                                          mlir::SmallVectorImpl<mlir::Type>& inferredReturnTypes) {
    const auto loc = optLoc.value_or(mlir::UnknownLoc::get(ctx));

    VPU::MatMulOpAdaptor matMul(operands, attrs);
    if (mlir::failed(matMul.verify(loc))) {
        return mlir::failure();
    }

    const auto inType1 = matMul.getInput1().getType().cast<vpux::NDTypeInterface>();
    const auto inType2 = matMul.getInput2().getType().cast<vpux::NDTypeInterface>();
    const auto inShape1 = inType1.getShape();
    const auto inShape2 = inType2.getShape();

    const auto inRank1 = inShape1.size();
    const auto inRank2 = inShape2.size();
    const auto transA = matMul.getTransposeA();
    const auto transB = matMul.getTransposeB();

    // Rightmost two axes are row & col. Remaining left axes are batch
    constexpr int kRowColIdxRange = 2;

    SmallVector<int64_t> outShape;
    outShape.reserve(std::max(inRank1, inRank2));

    // Temporally transformed shapes
    auto inShape1Trans = to_small_vector(inShape1);
    auto inShape2Trans = to_small_vector(inShape2);
    std::reverse(inShape1Trans.begin(), inShape1Trans.end());
    std::reverse(inShape2Trans.begin(), inShape2Trans.end());

    // Apply transpose only when rank >= 2
    if (transA && (inRank1 > 1)) {
        std::swap(inShape1Trans[0], inShape1Trans[1]);
    }
    if (transB && (inRank2 > 1)) {
        std::swap(inShape2Trans[0], inShape2Trans[1]);
    }

    // Only use the dim when it is Mat
    if (inRank2 >= kRowColIdxRange) {
        outShape.push_back(inShape2Trans[0]);
    }
    if (inRank1 >= kRowColIdxRange) {
        outShape.push_back(inShape1Trans[1]);
    }

    // Process batch axes
    uint32_t idx1 = kRowColIdxRange;
    uint32_t idx2 = kRowColIdxRange;

    while (idx1 < inRank1 || idx2 < inRank2) {
        if (idx1 < inRank1 && idx2 < inRank2) {
            outShape.push_back(std::max(inShape1Trans[idx1], inShape2Trans[idx2]));
            ++idx1;
            ++idx2;
        } else if (idx2 >= inRank2) {
            outShape.push_back(inShape1Trans[idx1]);
            ++idx1;
        } else if (idx1 >= inRank1) {
            outShape.push_back(inShape2Trans[idx2]);
            ++idx2;
        }
    }
    std::reverse(std::begin(outShape), std::end(outShape));

    const auto outType = inType1.changeShape(Shape(outShape));
    inferredReturnTypes.push_back(outType);
    return mlir::success();
}

namespace {

bool isSupported(VPU::ArchKind arch, ShapeRef input1Shape, ShapeRef input2Shape, bool transposeA = false,
                 bool transposeB = false) {
    if (arch != VPU::ArchKind::NPU40XX) {
        return false;
    }

    if (input1Shape.size() < 2 || input2Shape.size() < 2) {
        return false;
    }

    SmallVector<int64_t> input1HeightWidth{input1Shape[Dim(input1Shape.size() - 2)],
                                           input1Shape[Dim(input1Shape.size() - 1)]};
    SmallVector<int64_t> input2HeightWidth{input2Shape[Dim(input2Shape.size() - 2)],
                                           input2Shape[Dim(input2Shape.size() - 1)]};

    if (transposeA) {
        std::swap(input1HeightWidth[0], input1HeightWidth[1]);
    }

    if (transposeB) {
        std::swap(input2HeightWidth[0], input2HeightWidth[1]);
    }

    // The list of specialized configurations implemented in ASM.
    static const std::unordered_set<std::pair<SmallVector<int64_t>, SmallVector<int64_t>>> supportedHeightWidthConfigs{
            {{{49, 32}, {32, 49}}, {{49, 49}, {49, 32}}}};

    return supportedHeightWidthConfigs.find({input1HeightWidth, input2HeightWidth}) !=
           supportedHeightWidthConfigs.end();
}

}  // namespace

//
// isSupported
//

bool vpux::VPU::MatMulOp::isSupported(vpux::IE::MatMulOp matmulOp) {
    return ::isSupported(VPU::getArch(matmulOp), getShape(matmulOp.getInput1()), getShape(matmulOp.getInput2()),
                         matmulOp.getTransposeA(), matmulOp.getTransposeB());
}

//
// verify
//

mlir::LogicalResult vpux::VPU::MatMulOp::verify() {
    if (getTransposeA() || getTransposeB()) {
        return mlir::failure();
    }

    const auto operation = getOperation();
    const auto arch = VPU::getArch(operation);
    if (::isSupported(arch, getShape(getInput1()), getShape(getInput2()))) {
        return mlir::success();
    }

    return mlir::failure();
}

//
// TilingBuilderOpInterface
//

vpux::InputTiling vpux::VPU::MatMulOp::backInferTileInfo(const vpux::TileInfo& outputTile, vpux::Logger /*log*/) {
    const auto input1Shape = getShape(getInput1());
    const auto input2Shape = getShape(getInput2());
    TileInfo input1Tile(outputTile);
    TileInfo input2Tile(outputTile);

    input1Tile.shape[Dim(input1Tile.shape.size() - 2)] = input1Shape[Dim(input1Shape.size() - 2)];
    input1Tile.shape[Dim(input1Tile.shape.size() - 1)] = input1Shape[Dim(input1Shape.size() - 1)];

    input2Tile.shape[Dim(input2Tile.shape.size() - 2)] = input2Shape[Dim(input2Shape.size() - 2)];
    input2Tile.shape[Dim(input2Tile.shape.size() - 1)] = input2Shape[Dim(input2Shape.size() - 1)];

    return InputTiling{{std::move(input1Tile), std::move(input2Tile)}};
}

void vpux::VPU::MatMulOp::adjustAttrs(const TilingInfo& /*inputTiling*/, const TileInfo& /*outputTile*/) {
}

mlir::FailureOr<OutputTiling> vpux::VPU::MatMulOp::getTilingStrategy(TilingMode tilingMode, Logger log) {
    auto op = this->getOperation();
    SmallVector<int64_t> maxNumTiles;

    const auto outputType = getOutput().getType().cast<vpux::NDTypeInterface>();
    const auto outputRank = outputType.getShape().size();

    SmallVector<int64_t> axes{checked_cast<int64_t>(outputRank - 2), checked_cast<int64_t>(outputRank - 1)};
    maxNumTiles = getMaxNumTilesWithAxesExclusion(op, axes);

    return vpux::getSWLayerTilingStrategy(op, tilingMode, std::move(log), maxNumTiles);
}

//
// ClusteredOpInterface
//

bool vpux::VPU::MatMulOp::checkStrategyCompatibility(VPU::MultiClusterStrategy strategy, size_t numTiles) {
    const auto input1Shape = getInput1().getType().cast<vpux::NDTypeInterface>().getShape();
    const auto input2Shape = getInput2().getType().cast<vpux::NDTypeInterface>().getShape();

    return strategy == VPU::MultiClusterStrategy::SplitOverKernel &&
           input1Shape[Dims4D::Act::C] >= checked_cast<int64_t>(numTiles) &&
           input2Shape[Dims4D::Act::C] >= checked_cast<int64_t>(numTiles);
}

bool VPU::MatMulOp::doesLayerFitIntoCMX(VPU::MultiClusterStrategy strategy, Byte reservedMem) {
    auto matmulOp = mlir::cast<VPU::MatMulOp>(getOperation());
    const auto outputType = matmulOp.getOutput().getType().cast<vpux::NDTypeInterface>();
    auto numClusters = VPU::getOptimalNumClusters(matmulOp, outputType.getShape()[Dims4D::Act::C], strategy);
    auto distInput1Type =
            getDistributedActivationTypeFromOp(matmulOp, matmulOp.getInput1().getType(), numClusters, strategy);
    auto distInput2Type =
            getDistributedActivationTypeFromOp(matmulOp, matmulOp.getInput2().getType(), numClusters, strategy);
    auto distOutputType =
            getDistributedOutputTypeFromOp(matmulOp, matmulOp.getOutput().getType(), numClusters, strategy);
    return fitIntoCMX({distInput1Type, distInput2Type, distOutputType}, reservedMem);
}

vpux::VPU::DistributedTensorAttr vpux::VPU::MatMulOp::getExplicitDistributedTensorAttr(
        vpux::ShapeRef shape, vpux::VPU::DistributionMode distributionMode, mlir::ArrayAttr numTiles,
        mlir::IntegerAttr numClusters, mlir::ArrayAttr alignment, mlir::UnitAttr uniformDistributedSegments,
        const vpux::VPU::OverlapDistributionParams& /*overlapParams*/) {
    return vpux::VPU::getSWExplicitDistributedTensorAttr(mlir::dyn_cast<VPU::SWOpInterface>(getOperation()), shape,
                                                         distributionMode, numTiles, numClusters, alignment,
                                                         uniformDistributedSegments);
}

bool vpux::VPU::MatMulOp::fitIntoCMX(llvm::ArrayRef<vpux::NDTypeInterface> buffers, Byte reservedMem) {
    VPUX_THROW_UNLESS(buffers.size() == 3, "MatMulOp requires 2 inputs and 1 output, but the number of buffers is {0}",
                      buffers.size());

    SmallVector<Byte> buffersSize;
    std::transform(buffers.begin(), buffers.end(), std::back_inserter(buffersSize), [](const auto buffer) {
        return buffer.getTotalAllocSize();
    });

    auto totalAvailableCMXSize = reservedMem.count() == 0 ? getTotalCMXSize(getOperation()).count()
                                                          : getTotalCMXFragmentationAwareSize(getOperation()).count();

    return vpux::VPU::calculateAlignedBuffersMemoryRequirement(getArch(getOperation()), buffersSize).count() +
                   reservedMem.count() <=
           totalAvailableCMXSize;
}

bool vpux::VPU::MatMulOp::fitIntoCMX(llvm::ArrayRef<vpux::NDTypeInterface> buffers) {
    return fitIntoCMX(buffers, Byte(0));
}

bool vpux::VPU::MatMulOp::supportCycleCostCalculation() {
    return false;
}

//
// build
//

void vpux::VPU::MatMulOp::build(::mlir::OpBuilder& builder, ::mlir::OperationState& state, ::mlir::Value input1,
                                ::mlir::Value input2, ::mlir::UnitAttr transpose_a, ::mlir::UnitAttr transpose_b) {
    build(builder, state, input1, input2, transpose_a, transpose_b, {});
}
